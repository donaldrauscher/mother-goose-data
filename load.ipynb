{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13a5fb5-c19e-4381-bdc9-b1604dd135f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('schema.yaml', 'r') as f:\n",
    "    col = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f2817a-01e3-4223-a998-bfdd1ea095b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "awk_input = []\n",
    "for c, width in col:\n",
    "    if not c.startswith('FILLER'):\n",
    "        awk_input.append(f'substr($0,{start},{width})')\n",
    "    start += width\n",
    "\n",
    "awk_input = ', '.join(awk_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551a2ce3-0e93-4232-b881-ff7a6955c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "\n",
    "inputs = glob.glob('data/raw/*.txt')\n",
    "years = [re.compile(r'Nat([0-9]{4})PublicUS').search(i).group(1) for i in inputs]\n",
    "col_final = '|'.join([c for c, _ in col if not c.startswith('FILLER')])\n",
    "\n",
    "for y, i in zip(years, inputs):\n",
    "    !awk -v OFS='|' '{{ print $awk_input }}' $i > data/processed/births{y}.txt\n",
    "    !sed -i \"1i $col_final\" data/processed/births{y}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104aa697-c9cd-4497-ba7f-0e6d343bb69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/processed/births2016.txt [Content-Type=text/plain]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://data/processed/births2017.txt [Content-Type=text/plain]...\n",
      "Copying file://data/processed/births2018.txt [Content-Type=text/plain]...       \n",
      "Copying file://data/processed/births2019.txt [Content-Type=text/plain]...       \n",
      "\\ [4/4 files][  7.4 GiB/  7.4 GiB] 100% Done   1.8 MiB/s ETA 00:00:00           \n",
      "Operation completed over 4 objects/7.4 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r data/processed/*.txt gs://mother-goose-data/nvss/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2948514d-7a7c-4e56-927f-f445b575e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.job.load.LoadJob at 0x7fc44c24c100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "schema = [bigquery.SchemaField(c, \"INTEGER\" if c == 'DOB_YY' else \"STRING\") \\\n",
    "          for c, _ in col if not c.startswith('FILLER')]\n",
    "table = bigquery.Table('mother-goose-health.nvss.births', schema=schema)\n",
    "table.range_partitioning = bigquery.RangePartitioning(\n",
    "    field=\"DOB_YY\",\n",
    "    range_=bigquery.PartitionRange(start=1900, end=2100, interval=1),\n",
    ")\n",
    "\n",
    "client.delete_table('mother-goose-health.nvss.births', not_found_ok=True)\n",
    "table = client.create_table(table)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=schema,\n",
    "    skip_leading_rows=1,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    field_delimiter='|'\n",
    ")\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    'gs://mother-goose-data/nvss/*.txt', \n",
    "    table, \n",
    "    job_config=job_config\n",
    ")\n",
    "load_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a0801-9a12-4833-80e6-5f8d9cc71ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
